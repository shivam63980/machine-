{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc49a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b588dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    BOOKS=\"BOOKS\"\n",
    "    CLOTHING=\"CLOTHING\"\n",
    "\n",
    "xtrain=[\"i love the book\",\"this is great book\",\"the fit is great\",\"i love the shoes\"]\n",
    "ytrain=[Category.BOOKS,Category.BOOKS,Category.CLOTHING,Category.CLOTHING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512302dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']\n",
      "[[1 0 0 0 1 0 1 0]\n",
      " [1 0 1 1 0 0 0 1]\n",
      " [0 1 1 1 0 0 1 0]\n",
      " [0 0 0 0 1 1 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer(binary=True)\n",
    "vectors=vectorizer.fit_transform(xtrain)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ae50d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'fit', 'fit is', 'great', 'great book', 'is', 'is great', 'love', 'love the', 'shoes', 'the', 'the book', 'the fit', 'the shoes', 'this', 'this is']\n",
      "[[1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1]\n",
      " [0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer(binary=True,ngram_range=(1,2))\n",
    "xtrain_vectors=vectorizer.fit_transform(xtrain)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(xtrain_vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdc991d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm=svm.SVC(kernel='linear')\n",
    "clf_svm.fit(xtrain_vectors,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a66729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=vectorizer.transform(['shoes are alright'])\n",
    "\n",
    "clf_svm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc10ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4375f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f17ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love the book', 'this is great book', 'the fit is great', 'i love the shoes']\n"
     ]
    }
   ],
   "source": [
    "print(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9607fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.9804751e-01 -1.7059250e+00 -9.0664995e-01 -4.5425000e+00\n",
      " -1.1165801e+00 -2.9151249e+00  3.1752450e+00  4.0887251e+00\n",
      " -3.4474750e+00  2.3840599e+00  6.4857249e+00  2.3083498e+00\n",
      " -8.6464500e+00  2.0437698e+00  2.2699749e+00 -1.0261000e+00\n",
      "  4.0915399e+00 -7.4801493e-01  1.1435002e-01 -1.9810501e+00\n",
      "  1.3855026e+00  1.7070000e+00 -2.9752648e+00 -1.9328325e+00\n",
      " -1.4255500e+00 -2.0426226e+00 -3.7064652e+00 -4.3784651e-01\n",
      " -2.0860374e+00  4.4308500e+00 -1.0481000e+00 -7.8117514e-01\n",
      " -1.6870000e+00  1.9781501e+00  1.4894226e+00 -2.8325254e-01\n",
      " -1.4800999e+00  1.4303375e+00  2.6068749e+00 -1.3935680e+00\n",
      " -4.5071498e-01  1.8592875e+00  6.0194993e-01 -2.0355899e+00\n",
      "  5.3853750e+00  3.3568425e+00 -2.6558499e+00 -2.5876875e+00\n",
      " -4.1877502e-01  1.1819749e+00 -1.0135007e-01 -1.6391747e+00\n",
      " -7.5115502e-01 -2.4396350e+00 -5.0018353e+00  4.4182479e-02\n",
      " -1.1361099e+00  3.4045234e+00  4.4069252e+00  1.5867125e+00\n",
      "  7.3212752e+00 -6.2377250e-01 -3.5406952e+00 -1.5487249e+00\n",
      " -2.7915027e+00  4.5692497e-01 -2.8675752e+00 -2.1574497e+00\n",
      "  3.5327253e+00  2.9429674e+00 -3.0028498e+00  4.0561576e+00\n",
      " -2.2131751e+00 -2.7301099e+00  2.2525599e+00  6.7574859e-02\n",
      " -2.9405074e+00  1.8029499e+00 -1.1789126e+00 -2.1746502e+00\n",
      " -2.1985504e-01  1.1351575e+00  3.9773331e+00 -1.4294751e+00\n",
      "  2.7083826e-01  2.8169625e+00  3.3689499e+00 -3.6275029e-02\n",
      " -6.6733754e-01 -2.0622499e+00  5.5217499e-01  2.1563876e+00\n",
      "  5.8253503e+00 -5.5494246e+00 -3.5856503e-01 -1.6503401e+00\n",
      " -1.3458250e+00 -1.4840007e-01  1.7622524e+00 -9.1479999e-01\n",
      "  2.1465900e+00  4.4622073e+00  3.2821400e+00  1.8457750e+00\n",
      " -1.8648493e-01  9.6283495e-01 -1.4834499e+00  4.0102500e-01\n",
      " -2.9797997e+00  7.9937494e-01  2.4522400e+00 -1.5166250e+00\n",
      " -3.7715238e-01  2.3985500e+00  3.3255002e-01  1.7986224e+00\n",
      " -6.8490005e-01 -5.1091760e-01 -1.8716326e+00 -8.0151993e-01\n",
      " -1.2196251e+00 -2.4377999e+00 -8.4822536e-01  4.4465375e+00\n",
      "  1.9551001e+00 -4.5647252e-01  1.1451000e+00 -2.7702999e+00\n",
      " -5.0074500e-01 -1.2053250e+00 -5.6294746e+00  1.9835000e+00\n",
      " -2.7191000e+00 -1.5045950e+00  6.9217503e-01  2.5230401e+00\n",
      " -2.1575000e+00 -1.4835875e+00  3.3636250e+00 -1.8662750e+00\n",
      " -2.0677674e+00  1.4370599e+00  1.0521392e+00  2.1033750e+00\n",
      " -2.1464827e+00  5.6450999e-01  5.3212500e-01 -8.3847724e-02\n",
      " -6.6377509e-01  6.8043244e-01 -2.0621850e+00  2.8536501e+00\n",
      " -1.7352247e+00 -2.8443000e+00 -5.3201753e-01  8.3302242e-01\n",
      "  3.7822717e-01  9.0502751e-01 -9.2559004e-01  2.6364100e-01\n",
      " -2.1059022e+00 -4.7094274e+00 -2.3757493e-01  1.3409747e-01\n",
      " -1.4695925e+00  1.1836300e+00 -1.7678249e+00 -2.0474751e+00\n",
      " -3.1015801e+00 -2.7474751e+00  2.3939500e+00  2.9119998e-01\n",
      " -6.4154994e-01  2.9983025e+00  2.3853002e+00 -3.8257499e+00\n",
      "  4.6561250e-01  2.4625850e+00 -4.1938251e-01  6.9829524e-01\n",
      " -7.1579993e-01 -1.4624953e-02  3.2372375e+00 -3.2502999e+00\n",
      "  4.5349836e-02  4.1063027e+00 -2.2001500e+00 -1.6467290e+00\n",
      "  3.1262751e+00  1.4225700e+00  3.6304951e-02  1.4041975e+00\n",
      " -1.5605751e+00  2.3753252e+00  2.6392999e+00 -1.5464250e+00\n",
      " -5.9728498e+00  1.9010249e+00 -1.8664751e+00  5.6060200e+00\n",
      " -9.5827496e-01 -1.9006126e+00 -4.8451276e+00 -5.8231246e-01\n",
      " -7.2317505e-01 -2.2110374e+00  8.1549001e-01 -1.0414025e+00\n",
      "  1.9058951e+00 -3.8605497e+00  3.5286000e+00  1.3662599e+00\n",
      "  2.2550497e+00  2.5063176e+00 -2.7124995e-01  1.9068251e+00\n",
      " -2.3303626e+00 -3.5958242e-01  7.9588258e-01 -1.6820974e+00\n",
      " -3.7828848e+00  2.2385600e+00 -2.3069249e-01  3.8866749e+00\n",
      " -2.9949999e+00 -7.2774887e-02 -5.2936137e-01  2.3862777e+00\n",
      "  2.7844000e+00  2.0868599e+00 -1.0202500e+00 -6.6188755e+00\n",
      "  2.5358500e+00  2.3292500e-01 -1.5609975e+00  1.4913775e+00\n",
      "  4.9717754e-01  6.1425052e+00 -9.3077004e-01 -1.0970299e+00\n",
      " -3.2835951e+00 -4.0366502e+00  2.8092499e+00  5.4461503e-01\n",
      "  5.1136999e+00 -4.7508508e-01 -3.0958500e+00 -1.6869251e+00\n",
      "  5.5714927e+00 -5.8892751e-01 -2.1862252e+00  7.2488189e-04\n",
      " -5.1041250e+00 -2.0981116e+00 -3.4806490e-01 -1.5959325e+00\n",
      " -4.2672509e-01  1.1591926e+00 -3.7716749e+00  2.1917500e+00\n",
      "  2.8775399e+00  3.8451598e+00  4.2834749e+00  2.1570098e+00\n",
      "  2.5055449e+00 -1.2231750e+00  4.1285264e-01  1.1988211e+00\n",
      " -4.9739499e+00  1.0778250e+00  4.2271227e-01 -3.8091974e+00\n",
      " -3.7465799e+00 -1.0162874e+00 -1.5726924e+00 -3.8487256e-01\n",
      "  2.0939450e+00 -3.7680500e+00  2.6195997e-01  2.4638376e+00\n",
      " -1.9473826e+00 -1.5511725e+00  3.0020747e+00  4.0775223e+00\n",
      "  4.7141755e-01 -1.4983499e-01  2.5353000e+00  2.0879149e+00\n",
      " -1.3202243e-01 -2.3845255e-01  4.0010076e+00  1.6600013e-02\n",
      "  4.4546151e+00 -1.3000700e+00 -2.6352043e+00  1.1399500e+00\n",
      "  1.8315576e+00 -2.9688001e+00 -7.6453247e+00  8.4300494e-01]\n"
     ]
    }
   ],
   "source": [
    "docs=[nlp(text) for text in xtrain]\n",
    "print(docs[0].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92329c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[nlp(text) for text in xtrain]\n",
    "xtrain_word_vectors=[x.vector for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5759bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm_wv=svm.SVC(kernel='linear')\n",
    "clf_svm_wv.fit(xtrain_word_vectors,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac0eb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=[\"i love the these earning and its hurt\"]\n",
    "test_docs=[nlp(text) for text in xtest]\n",
    "xtest_word_vectors=[x.vector for x in test_docs]\n",
    "clf_svm_wv.predict(xtest_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08470d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING', 'CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=[\"i went to the bank and wrote a check\",\"let me check that out\"]\n",
    "test_docs=[nlp(text) for text in xtest]\n",
    "xtest_word_vectors=[x.vector for x in test_docs]\n",
    "clf_svm_wv.predict(xtest_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9461cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a5d111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abxxxcd']\n"
     ]
    }
   ],
   "source": [
    "regexp=re.compile(r\"^ab[^\\s]*cd$\")\n",
    "phrases=[\"abcd\",\"xxx\",\"abxxxcd\",\"ab cd\"]\n",
    "matches=[]\n",
    "for phrase in phrases:\n",
    "    if re.match(regexp,phrase):\n",
    "        matches.append(phrase)\n",
    "        \n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "294b9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd']\n"
     ]
    }
   ],
   "source": [
    "regexp=re.compile(r\"ab[^\\s]*cd\")\n",
    "phrases=[\"abcd\",\"xxx\",\"aaa abxxxcd ccc\",\"ab cd\"]\n",
    "matches=[]\n",
    "for phrase in phrases:\n",
    "    if re.match(regexp,phrase):\n",
    "        matches.append(phrase)\n",
    "        \n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e61146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'aaa abxxxcd ccc']\n"
     ]
    }
   ],
   "source": [
    "regexp=re.compile(r\"ab[^\\s]*cd\")\n",
    "phrases=[\"abcd\",\"xxx\",\"aaa abxxxcd ccc\",\"ab cd\"]\n",
    "matches=[]\n",
    "for phrase in phrases:\n",
    "    if re.search(regexp,phrase):\n",
    "        matches.append(phrase)\n",
    "        \n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f35bc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i liked that story', 'i like that book']\n"
     ]
    }
   ],
   "source": [
    "regexp=re.compile(r\"read|story|book\")\n",
    "phrases=[\"i liked that story\",\"i like that book\",\"that hat is very nice\"]\n",
    "matches=[]\n",
    "for phrase in phrases:\n",
    "    if re.search(regexp,phrase):\n",
    "        matches.append(phrase)\n",
    "        \n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dc82360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i liked that history', 'the car treaded up the hill ']\n"
     ]
    }
   ],
   "source": [
    "regexp=re.compile(r\"read|story|book\")\n",
    "phrases=[\"i liked that history\",\"the car treaded up the hill \",\"that hat is very nice\"]\n",
    "matches=[]\n",
    "for phrase in phrases:\n",
    "    if re.search(regexp,phrase):\n",
    "        matches.append(phrase)\n",
    "        \n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "809a7bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i liked that story']\n"
     ]
    }
   ],
   "source": [
    "regexp=re.compile(r\"\\bread\\b|\\bstory\\b|\\bbook\")\n",
    "phrases=[\"i liked that story\",\"the car treaded up the hill \",\"that hat is very nice\"]\n",
    "matches=[]\n",
    "for phrase in phrases:\n",
    "    if re.search(regexp,phrase):\n",
    "        matches.append(phrase)\n",
    "        \n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef1b1a",
   "metadata": {},
   "source": [
    "# Stemming / Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4612b824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "847e3a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read the book'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "phrase=\"reading the books\"\n",
    "\n",
    "words=word_tokenize(phrase)\n",
    "stemmed_words=[]\n",
    "for word in words:\n",
    "    stemmed_words.append(stemmer.stem(word))\n",
    "    \n",
    "# stemmer.stem(phrase)\n",
    "\" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2573ae0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stori'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "phrase=\"stories\"\n",
    "\n",
    "words=word_tokenize(phrase)\n",
    "stemmed_words=[]\n",
    "for word in words:\n",
    "    stemmed_words.append(stemmer.stem(word))\n",
    "    \n",
    "# stemmer.stem(phrase)\n",
    "\" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a41ad29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read the book .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "phrase=\"reading the books.\"\n",
    "\n",
    "words=word_tokenize(phrase)\n",
    "stemmed_words=[]\n",
    "for word in words:\n",
    "    stemmed_words.append(stemmer.stem(word))\n",
    "    \n",
    "# stemmer.stem(phrase)\n",
    "\" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d726c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reading the book'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "phrase=\"reading the books\"\n",
    "words=word_tokenize(phrase)\n",
    "lemmatized_words=[]\n",
    "for word in words:\n",
    "    lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "\" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5481079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read the book'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "phrase=\"reading the books\"\n",
    "words=word_tokenize(phrase)\n",
    "lemmatized_words=[]\n",
    "for word in words:\n",
    "    lemmatized_words.append(lemmatizer.lemmatize(word,pos='v'))\n",
    "\n",
    "\" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8518e83",
   "metadata": {},
   "source": [
    "# Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a01d2ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "print(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db9700d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d92861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here example sentence demostrating removal stopwords'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "phrase=\"Here is an example of sentence demostrating the removal of stopwords\"\n",
    "\n",
    "words=word_tokenize(phrase)\n",
    "stripped_phrase=[]\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        stripped_phrase.append(word)\n",
    "\" \".join(stripped_phrase)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8925b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love book great book fit great love shoes'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "phrase=\"i love the book this is great book the fit is great i love the shoes\"\n",
    "\n",
    "words=word_tokenize(phrase)\n",
    "stripped_phrase=[]\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        stripped_phrase.append(word)\n",
    "\" \".join(stripped_phrase)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ab177",
   "metadata": {},
   "source": [
    "# Various other techniques (spell correction,sentiment,&pos tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85bf055b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"this is an example\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "phrase=\"this is an example\"\n",
    "tb_phrase=TextBlob(phrase)\n",
    "tb_phrase.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4d512d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"this is an example\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=\"thiss is aan exxamplee\"\n",
    "tb_phrase=TextBlob(phrase)\n",
    "tb_phrase.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76256e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'), ('read', 'VBD'), ('the', 'DT'), ('book', 'NN')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=\"i read the book\"\n",
    "tb_phrase=TextBlob(phrase)\n",
    "tb_phrase.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "775b2e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=\"the book sucked it was so bad\"\n",
    "tb_phrase=TextBlob(phrase)\n",
    "tb_phrase.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96b084dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase=\"i read the  book\"\n",
    "tb_phrase=TextBlob(phrase)\n",
    "tb_phrase.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965881c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
